{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import necessary libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-29T09:19:06.127062Z","iopub.status.busy":"2024-05-29T09:19:06.126470Z","iopub.status.idle":"2024-05-29T09:19:06.138296Z","shell.execute_reply":"2024-05-29T09:19:06.136728Z","shell.execute_reply.started":"2024-05-29T09:19:06.127016Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd \n","from sklearn.svm import SVC\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import accuracy_score\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from skimage.feature import hog\n","import lightgbm as lgb"]},{"cell_type":"markdown","metadata":{},"source":["# Get paths"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Directories\n","train_dir = 'Data/train'\n","val_dir = 'Data/val'\n","test_dir = 'Data/test'"]},{"cell_type":"markdown","metadata":{},"source":["# Data processing"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def compute_color_histogram(image, bins=(8, 8, 8)):\n","    # Convert the image to HSV color space\n","    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    # Compute the color histogram\n","    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n","    # Normalize the histogram\n","    hist = cv2.normalize(hist, hist).flatten()\n","    return hist\n","\n","def load_images(folder_path, flower_types):\n","    features = []\n","    labels = []\n","    for flower in flower_types:\n","        flower_folder = os.path.join(folder_path, flower)\n","        for img in os.listdir(flower_folder):\n","            img_path = os.path.join(flower_folder, img)\n","            image = cv2.imread(img_path)\n","            if image is None:\n","                continue\n","            image = np.array(image).astype('uint8')\n","            image = cv2.resize(image, (64, 64))\n","            grey_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","            # Extract HOG features\n","            hog_features = hog(grey_image, orientations=9, pixels_per_cell=(8, 8),\n","                               cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")\n","\n","            # Extract color histogram features\n","            color_hist = compute_color_histogram(image)\n","\n","            # Concatenate HOG and color histogram features\n","            combined_features = np.hstack((hog_features, color_hist))\n","\n","            features.append(combined_features)\n","            labels.append(flower)\n","\n","    return np.array(features), np.array(labels)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 5981\n","Number of validation samples: 1709\n","Number of testing samples: 857\n"]}],"source":["flower_types = [folder for folder in os.listdir(train_dir)]\n","\n","X_train, y_train = load_images(train_dir, flower_types)\n","X_val, y_val = load_images(val_dir, flower_types)\n","X_test, y_test = load_images(test_dir, flower_types)\n","\n","# Kiểm tra dữ liệu sau khi tải\n","print(f\"Number of training samples: {len(X_train)}\")\n","print(f\"Number of validation samples: {len(X_val)}\")\n","print(f\"Number of testing samples: {len(X_test)}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Label to Encoded Mapping:\n","daisy -> 0\n","lily -> 1\n","orchid -> 2\n","sunflower -> 3\n","tulip -> 4\n"]}],"source":["# Encode labels\n","encoder = LabelEncoder()\n","y_train_encoded = encoder.fit_transform(y_train)\n","y_val_encoded = encoder.transform(y_val)\n","y_test_encoded = encoder.transform(y_test)\n","\n","print(\"Label to Encoded Mapping:\")\n","for original_label, encoded_label in zip(encoder.classes_, range(len(encoder.classes_))):\n","    print(f\"{original_label} -> {encoded_label}\")\n","\n","# Standardize data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5981, 2276)\n","(5981, 782)\n"]}],"source":["# Apply PCA\n","pca = PCA(n_components=0.95)\n","print(X_train.shape)\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","print(X_train_pca.shape)\n","X_val_pca = pca.transform(X_val_scaled)\n","X_test_pca = pca.transform(X_test_scaled)"]},{"cell_type":"markdown","metadata":{},"source":["# Initiating necessary functions"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["def evaluate_model(model, X_train, X_val, y_train, y_val):\n","    # Huấn luyện mô hình\n","    model.fit(X_train, y_train)\n","    # Dự đoán trên tập validation\n","    y_pred = model.predict(X_val)\n","\n","    # Tính các chỉ số đánh giá\n","    accuracy = accuracy_score(y_val, y_pred)\n","\n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["# SVM"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy with kernel = linear, C = 0.01: 0.7899356348741955\n","Accuracy with kernel = linear, C = 0.1: 0.7893504973668812\n","Accuracy with kernel = linear, C = 1: 0.7893504973668812\n","Accuracy with kernel = linear, C = 5: 0.7893504973668812\n","Accuracy with kernel = linear, C = 10: 0.7893504973668812\n","Accuracy with kernel = linear, C = 15: 0.7893504973668812\n","Accuracy with kernel = linear, C = 20: 0.7893504973668812\n","Accuracy with kernel = rbf, C = 0.01: 0.21650087770626097\n","Accuracy with kernel = rbf, C = 0.1: 0.7612638970157987\n","Accuracy with kernel = rbf, C = 1: 0.8624926857811586\n","Accuracy with kernel = rbf, C = 5: 0.8671737858396723\n","Accuracy with kernel = rbf, C = 10: 0.8671737858396723\n","Accuracy with kernel = rbf, C = 15: 0.8671737858396723\n","Accuracy with kernel = rbf, C = 20: 0.8671737858396723\n","Accuracy with kernel = poly, C = 0.01: 0.21650087770626097\n","Accuracy with kernel = poly, C = 0.1: 0.21825629022820361\n","Accuracy with kernel = poly, C = 1: 0.7027501462843768\n","Accuracy with kernel = poly, C = 5: 0.7284961966062025\n","Accuracy with kernel = poly, C = 10: 0.732592159157402\n","Accuracy with kernel = poly, C = 15: 0.732592159157402\n","Accuracy with kernel = poly, C = 20: 0.732592159157402\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["kernels = ['linear', 'rbf', 'poly']\n","C_values  = [0.01, 0.1, 1, 5, 10, 15, 20] \n","df_svm = pd.DataFrame(index=C_values, columns=kernels)\n","output_dir = r'finetunning_result\\svm.csv' \n","\n","with open(output_dir, 'w') as f:\n","    for kernel in kernels: \n","        for C in C_values : \n","            model = SVC(kernel=kernel, C = C) \n","            accuracy = evaluate_model(model=model, X_train= X_train_pca, X_val=X_val_pca, y_train=y_train_encoded, y_val= y_val_encoded)\n","            df_svm.at[C, kernel] = accuracy\n","            print(f'Accuracy with kernel = {kernel}, C = {C}: {accuracy}')\n","# Save the DataFrame to a CSV file\n","df_svm.to_csv(output_dir, index=True)"]},{"cell_type":"markdown","metadata":{},"source":["# LightGBM"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056763 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 199410\n","[LightGBM] [Info] Number of data points in the train set: 5981, number of used features: 782\n","[LightGBM] [Info] Start training from score -1.580761\n","[LightGBM] [Info] Start training from score -1.664602\n","[LightGBM] [Info] Start training from score -1.530077\n","[LightGBM] [Info] Start training from score -1.607100\n","[LightGBM] [Info] Start training from score -1.671694\n","Accuracy with learning_rate = 0.05: 0.7864248098303102\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027827 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 199410\n","[LightGBM] [Info] Number of data points in the train set: 5981, number of used features: 782\n","[LightGBM] [Info] Start training from score -1.580761\n","[LightGBM] [Info] Start training from score -1.664602\n","[LightGBM] [Info] Start training from score -1.530077\n","[LightGBM] [Info] Start training from score -1.607100\n","[LightGBM] [Info] Start training from score -1.671694\n","Accuracy with learning_rate = 0.1: 0.7952018724400234\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048292 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 199410\n","[LightGBM] [Info] Number of data points in the train set: 5981, number of used features: 782\n","[LightGBM] [Info] Start training from score -1.580761\n","[LightGBM] [Info] Start training from score -1.664602\n","[LightGBM] [Info] Start training from score -1.530077\n","[LightGBM] [Info] Start training from score -1.607100\n","[LightGBM] [Info] Start training from score -1.671694\n","Accuracy with learning_rate = 0.15: 0.8033937975424225\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044055 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 199410\n","[LightGBM] [Info] Number of data points in the train set: 5981, number of used features: 782\n","[LightGBM] [Info] Start training from score -1.580761\n","[LightGBM] [Info] Start training from score -1.664602\n","[LightGBM] [Info] Start training from score -1.530077\n","[LightGBM] [Info] Start training from score -1.607100\n","[LightGBM] [Info] Start training from score -1.671694\n","Accuracy with learning_rate = 0.2: 0.8115857226448215\n"]}],"source":["learning_rates =  [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4] \n","output_dir = r'finetunning_result\\lightGBM.csv'\n","df_lightGBM = pd.DataFrame(columns=learning_rates)\n","\n","\n","for lr in learning_rates: \n","    model = lgb.LGBMClassifier(objective= 'multiclass',\n","                              num_class = 5, \n","                              learning_rate = lr, \n","                              )\n","    accuracy = evaluate_model(model, X_train=X_train_pca, X_val=X_val_pca, y_train = y_train_encoded, y_val = y_val_encoded)\n","    print(f'Accuracy with learning_rate = {lr}: {accuracy}')\n","    df_lightGBM[0,lr] = accuracy\n","\n","df_lightGBM.to_csv(output_dir, index=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the parameters\n","num_estimators =  [300, 500, 800, 1000, 1200]  \n","output_dir = r'finetunning_result\\random_forest.csv'\n","df_random_forest = pd.DataFrame(columns=num_estimators)\n","\n","# Iterate over the number of estimators and evaluate the model\n","for n in num_estimators:\n","    model = RandomForestClassifier(n_estimators=n)\n","    accuracy = evaluate_model(model, X_train=X_train_pca, X_val=X_val_pca, y_train=y_train_encoded, y_val=y_val_encoded)\n","    print(f'Accuracy with n_estimators = {n}: {accuracy}')\n","    df_random_forest.at[0, n] = accuracy\n","\n","# Save the DataFrame to a CSV file\n","df_random_forest.to_csv(output_dir, index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1170109,"sourceId":1960165,"sourceType":"datasetVersion"},{"datasetId":2187552,"sourceId":3653473,"sourceType":"datasetVersion"},{"datasetId":3083976,"sourceId":5304701,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
